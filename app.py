"""
Interface utilisateur Streamlit pour l'agent IA d'analyse de donn√©es.
Interface moderne et intuitive pour l'interaction en langage naturel.
"""

import streamlit as st
import pandas as pd
import os
import base64
from datetime import datetime
from typing import Dict, Any, Optional
import logging

# Configuration de la page
st.set_page_config(
    page_title="Agent IA - Analyse de Donn√©es",
    page_icon="ü§ñ",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Imports des composants
from src.components.data_manager import DataManager
from src.components.semantic_cache import SemanticCache
from src.components.ai_agent import AIAgent

# Configuration du logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Variables d'environnement
from dotenv import load_dotenv
load_dotenv()

# Configuration globale
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
CHROMA_DB_PATH = os.getenv("CHROMA_DB_PATH", "./chroma_db")
SEMANTIC_CACHE_THRESHOLD = float(os.getenv("SEMANTIC_CACHE_THRESHOLD", "0.85"))
CACHE_DIR = os.getenv("FAISS_INDEX_PATH", "./cache")


@st.cache_resource
def initialize_components():
    """Initialise les composants de l'application (mise en cache)."""
    try:
        # Initialiser les composants
        data_manager = DataManager(db_path=CHROMA_DB_PATH)
        semantic_cache = SemanticCache(
            threshold=SEMANTIC_CACHE_THRESHOLD,
            cache_dir=CACHE_DIR
        )
        
        if not OPENAI_API_KEY:
            st.error("‚ö†Ô∏è Cl√© API OpenAI manquante. Veuillez configurer votre fichier .env")
            st.stop()
        
        ai_agent = AIAgent(
            openai_api_key=OPENAI_API_KEY,
            data_manager=data_manager,
            semantic_cache=semantic_cache
        )
        
        return data_manager, semantic_cache, ai_agent
    
    except Exception as e:
        st.error(f"Erreur lors de l'initialisation: {e}")
        st.stop()


def main():
    """Fonction principale de l'application Streamlit."""
    
    # Titre de l'application
    st.title("ü§ñ Agent IA - Analyse de Donn√©es")
    st.markdown("""
    **Interagissez avec vos donn√©es en langage naturel**  
    Chargez vos fichiers CSV ou Excel et posez des questions en fran√ßais !
    """)
    
    # Initialiser les composants
    data_manager, semantic_cache, ai_agent = initialize_components()
    
    # Sidebar pour la gestion des fichiers
    with st.sidebar:
        st.header("üìÅ Gestion des Fichiers")
        
        # Upload de fichier
        uploaded_file = st.file_uploader(
            "Choisissez un fichier CSV ou Excel",
            type=['csv', 'xlsx', 'xls'],
            help="Formats support√©s: CSV, XLSX, XLS"
        )
        
        # Traitement du fichier upload√©
        if uploaded_file is not None:
            if st.button("üì§ Charger le fichier"):
                with st.spinner("Chargement et indexation du fichier..."):
                    # Sauvegarder le fichier temporairement
                    temp_path = f"./data/{uploaded_file.name}"
                    os.makedirs("./data", exist_ok=True)
                    
                    with open(temp_path, "wb") as f:
                        f.write(uploaded_file.getbuffer())
                    
                    # Charger dans ChromaDB
                    success_db = data_manager.load_data_file(temp_path)
                    
                    # Charger pour l'analyse pandas
                    success_agent = ai_agent.load_data_for_analysis(temp_path)
                    
                    if success_db and success_agent:
                        st.success(f"‚úÖ Fichier '{uploaded_file.name}' charg√© avec succ√®s!")
                        st.experimental_rerun()
                    else:
                        st.error("‚ùå Erreur lors du chargement du fichier")
        
        # Affichage des fichiers charg√©s
        st.subheader("üìä Fichiers Charg√©s")
        files_info = data_manager.get_file_info()
        
        if files_info:
            for file_id, info in files_info.items():
                with st.expander(f"üìÑ {info['file_name']}"):
                    st.write(f"**Lignes:** {info['num_rows']:,}")
                    st.write(f"**Colonnes:** {info['num_cols']}")
                    st.write("**Colonnes disponibles:**")
                    st.write(", ".join(info['columns']))
                    
                    if st.button(f"üóëÔ∏è Supprimer", key=f"delete_{file_id}"):
                        data_manager.remove_file(file_id)
                        st.success(f"Fichier {info['file_name']} supprim√©")
                        st.experimental_rerun()
        else:
            st.info("Aucun fichier charg√©")
        
        # Statistiques du cache
        st.subheader("üß† Cache S√©mantique")
        cache_stats = semantic_cache.get_stats()
        st.metric("Entr√©es en cache", cache_stats['total_entries'])
        st.metric("Seuil de similarit√©", f"{cache_stats['threshold']:.2f}")
        
        if st.button("üßπ Vider le cache"):
            semantic_cache.clear()
            st.success("Cache vid√© !")
    
    # Interface de chat principale
    st.header("üí¨ Chat avec vos Donn√©es")
    
    # Initialiser l'historique de chat dans la session
    if "messages" not in st.session_state:
        st.session_state.messages = []
    
    # Afficher l'historique des messages
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])
            
            # Afficher la visualisation si pr√©sente
            if "visualization" in message:
                display_visualization(message["visualization"])
    
    # Interface de saisie
    if prompt := st.chat_input("Posez votre question sur les donn√©es..."):
        # Ajouter le message utilisateur
        st.session_state.messages.append({"role": "user", "content": prompt})
        with st.chat_message("user"):
            st.markdown(prompt)
        
        # Traiter la requ√™te
        with st.chat_message("assistant"):
            with st.spinner("Analyse en cours..."):
                result = ai_agent.process_query(prompt)
                
                # Afficher la r√©ponse
                st.markdown(result['response'])
                
                # Afficher la source
                source_emoji = {
                    'cache': 'üß† (Cache)',
                    'pandas_agent': 'üêº (Analyse)',
                    'llm_with_context': 'ü§ñ (IA)',
                    'agent': 'üîß (Agent)',
                    'error': '‚ö†Ô∏è (Erreur)'
                }
                st.caption(f"Source: {source_emoji.get(result.get('source', 'unknown'), '‚ùì')}")
                
                # Afficher la visualisation si pr√©sente
                if 'visualization' in result and result['visualization']:
                    display_visualization(result['visualization'])
                    
                    # Sauvegarder le message avec visualisation
                    st.session_state.messages.append({
                        "role": "assistant", 
                        "content": result['response'],
                        "visualization": result['visualization']
                    })
                else:
                    # Sauvegarder le message sans visualisation
                    st.session_state.messages.append({
                        "role": "assistant", 
                        "content": result['response']
                    })
    
    # Section d'exemples de requ√™tes
    if not files_info:
        st.info("üí° **Astuce:** Chargez d'abord un fichier CSV ou Excel pour commencer l'analyse !")
    else:
        st.subheader("üí° Exemples de Requ√™tes")
        
        col1, col2, col3 = st.columns(3)
        
        with col1:
            st.markdown("""
            **üìä Analyse Descriptive**
            - "Montre-moi un r√©sum√© des donn√©es"
            - "Quelles sont les colonnes disponibles ?"
            - "Combien de lignes contient le dataset ?"
            """)
        
        with col2:
            st.markdown("""
            **üìà Visualisations**
            - "Cr√©e un histogramme de [colonne]"
            - "Montre la corr√©lation entre les variables"
            - "Fais un graphique en barres des cat√©gories"
            """)
        
        with col3:
            st.markdown("""
            **üîç Questions M√©tier**
            - "Quelle est la tendance des ventes ?"
            - "Trouve les valeurs aberrantes"
            - "Compare les performances par r√©gion"
            """)


def display_visualization(plot_base64: str):
    """Affiche une visualisation encod√©e en base64 avec bouton d'export."""
    try:
        # D√©coder et afficher l'image
        image_data = base64.b64decode(plot_base64)
        st.image(image_data, caption="Visualisation g√©n√©r√©e", use_column_width=True)
        
        # Bouton de t√©l√©chargement
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"visualization_{timestamp}.png"
        
        st.download_button(
            label="üì• T√©l√©charger l'image",
            data=image_data,
            file_name=filename,
            mime="image/png",
            key=f"download_{timestamp}"
        )
        
    except Exception as e:
        st.error(f"Erreur lors de l'affichage de la visualisation: {e}")


def show_data_preview():
    """Affiche un aper√ßu des donn√©es charg√©es."""
    data_manager, _, ai_agent = initialize_components()
    
    summary = ai_agent.get_data_summary()
    if 'message' not in summary:
        st.subheader("üìã Aper√ßu des Donn√©es")
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.metric("Nombre de lignes", f"{summary['shape'][0]:,}")
            st.metric("Nombre de colonnes", summary['shape'][1])
        
        with col2:
            missing_total = sum(summary['missing_values'].values())
            st.metric("Valeurs manquantes", f"{missing_total:,}")
        
        # Afficher les types de colonnes
        st.subheader("üè∑Ô∏è Types de Colonnes")
        dtypes_df = pd.DataFrame(list(summary['dtypes'].items()), 
                                columns=['Colonne', 'Type'])
        st.dataframe(dtypes_df, use_container_width=True)
        
        # √âchantillon de donn√©es
        st.subheader("üëÅÔ∏è √âchantillon de Donn√©es")
        sample_df = pd.DataFrame(summary['sample'])
        st.dataframe(sample_df, use_container_width=True)


# Interface de navigation par onglets
tab1, tab2, tab3 = st.tabs(["üí¨ Chat", "üìä Aper√ßu Donn√©es", "‚öôÔ∏è Configuration"])

with tab1:
    # Le contenu principal est d√©j√† affich√©
    pass

with tab2:
    show_data_preview()

with tab3:
    st.header("‚öôÔ∏è Configuration")
    
    # Statistiques g√©n√©rales
    data_manager, semantic_cache, _ = initialize_components()
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("üìä Statistiques ChromaDB")
        db_stats = data_manager.get_stats()
        st.json(db_stats)
    
    with col2:
        st.subheader("üß† Statistiques Cache")
        cache_stats = semantic_cache.get_stats()
        st.json(cache_stats)
    
    # Boutons d'administration
    st.subheader("üîß Administration")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        if st.button("üóëÔ∏è R√©initialiser la base de donn√©es"):
            if st.checkbox("Confirmer la r√©initialisation"):
                data_manager.reset_database()
                st.success("Base de donn√©es r√©initialis√©e !")
    
    with col2:
        if st.button("üßπ Vider le cache s√©mantique"):
            semantic_cache.clear()
            st.success("Cache s√©mantique vid√© !")
    
    with col3:
        if st.button("üìù Effacer l'historique de chat"):
            st.session_state.messages = []
            st.success("Historique effac√© !")


if __name__ == "__main__":
    main()
