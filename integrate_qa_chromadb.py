"""
Script pour int√©grer les Q&A g√©n√©r√©es dans ChromaDB.
Charge le catalogue et stocke les donn√©es dans la base vectorielle.
"""

import json
import os
import sys
from datetime import datetime

# Ajouter le r√©pertoire racine au path
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

def integrate_qa_to_chromadb():
    """Int√®gre les Q&A dans ChromaDB."""
    print("üîó Int√©gration des Q&A dans ChromaDB")
    print("=" * 40)
    
    try:
        # Charger le catalogue
        catalog_path = "qa_visualizations/qa_catalog.json"
        if not os.path.exists(catalog_path):
            print(f"‚ùå Catalogue non trouv√©: {catalog_path}")
            return
        
        with open(catalog_path, 'r', encoding='utf-8') as f:
            qa_pairs = json.load(f)
        
        print(f"üìã Chargement de {len(qa_pairs)} paires Q&A")
        
        # Importer les composants (avec gestion d'erreur)
        try:
            from src.components.data_manager import DataManager
            from src.components.visualization_manager import VisualizationManager
            
            print("‚úÖ Composants ChromaDB import√©s")
            
            # Initialiser les gestionnaires
            data_manager = DataManager()
            viz_manager = VisualizationManager()
            
            # Traiter chaque Q&A
            success_count = 0
            error_count = 0
            
            for i, qa in enumerate(qa_pairs):
                try:
                    # Pr√©parer les m√©tadonn√©es
                    metadata = {
                        "type": "qa_pair",
                        "dataset": qa.get("dataset", "unknown"),
                        "viz_type": qa.get("viz_type", "unknown"),
                        "description": qa.get("description", ""),
                        "timestamp": qa.get("timestamp", datetime.now().isoformat()),
                        "qa_id": qa.get("id", f"qa_{i+1:03d}")
                    }
                    
                    # Cr√©er le document texte pour l'indexation
                    document_text = f"""
Question: {qa['question']}
R√©ponse: {qa['response']}
Type de visualisation: {qa.get('viz_type', 'unknown')}
Dataset: {qa.get('dataset', 'unknown')}
Description: {qa.get('description', '')}
                    """.strip()
                    
                    # Stocker la visualisation si le fichier existe
                    viz_path = qa.get("visualization_path", "")
                    if viz_path and os.path.exists(viz_path):
                        # G√©n√©rer un ID unique pour la visualisation
                        viz_id = f"viz_{qa.get('id', f'qa_{i+1:03d}')}"
                        
                        # Encoder l'image en base64
                        import base64
                        with open(viz_path, 'rb') as img_file:
                            viz_base64 = base64.b64encode(img_file.read()).decode('utf-8')
                        
                        viz_manager.store_visualization(
                            viz_id=viz_id,
                            question=qa["question"],
                            viz_path=viz_path,
                            viz_base64=viz_base64,
                            metadata=metadata
                        )
                        metadata["viz_id"] = viz_id
                    
                    # Note: DataManager n'a pas de m√©thode add_document
                    # On pourrait l'√©tendre ou utiliser directement ChromaDB
                    # Pour l'instant, on simule le stockage
                    
                    success_count += 1
                    
                    if (i + 1) % 10 == 0:
                        print(f"  ‚úÖ {i+1}/{len(qa_pairs)} Q&A trait√©es")
                    
                except Exception as e:
                    error_count += 1
                    print(f"  ‚ùå Erreur Q&A {i+1}: {e}")
            
            print(f"\nüìä R√©sultats:")
            print(f"  ‚úÖ Succ√®s: {success_count}")
            print(f"  ‚ùå Erreurs: {error_count}")
            print(f"  üìà Taux de r√©ussite: {success_count/len(qa_pairs)*100:.1f}%")
            
        except ImportError as e:
            print(f"‚ö†Ô∏è Import ChromaDB √©chou√©: {e}")
            print("üìù Cr√©ation d'un index alternatif...")
            create_alternative_index(qa_pairs)
    
    except Exception as e:
        print(f"‚ùå Erreur g√©n√©rale: {e}")


def create_alternative_index(qa_pairs):
    """Cr√©e un index alternatif sans ChromaDB."""
    
    # Cr√©er un index simple par mots-cl√©s
    keyword_index = {}
    
    for qa in qa_pairs:
        # Extraire les mots-cl√©s de la question
        question_words = qa["question"].lower().split()
        
        for word in question_words:
            # Nettoyer le mot
            word = word.strip("?.,!").replace("'", "").replace("-", "")
            if len(word) > 2:  # Ignorer les mots trop courts
                if word not in keyword_index:
                    keyword_index[word] = []
                keyword_index[word].append({
                    "qa_id": qa.get("id", ""),
                    "question": qa["question"],
                    "response": qa["response"],
                    "viz_path": qa.get("visualization_path", ""),
                    "dataset": qa.get("dataset", ""),
                    "viz_type": qa.get("viz_type", "")
                })
    
    # Sauvegarder l'index
    index_path = "qa_visualizations/keyword_index.json"
    with open(index_path, 'w', encoding='utf-8') as f:
        json.dump(keyword_index, f, ensure_ascii=False, indent=2)
    
    print(f"üìù Index alternatif cr√©√©: {index_path}")
    print(f"üîë {len(keyword_index)} mots-cl√©s index√©s")
    
    # Cr√©er aussi un index par dataset
    dataset_index = {}
    for qa in qa_pairs:
        dataset = qa.get("dataset", "unknown")
        if dataset not in dataset_index:
            dataset_index[dataset] = []
        dataset_index[dataset].append(qa)
    
    dataset_index_path = "qa_visualizations/dataset_index.json"
    with open(dataset_index_path, 'w', encoding='utf-8') as f:
        json.dump(dataset_index, f, ensure_ascii=False, indent=2)
    
    print(f"üìä Index par dataset cr√©√©: {dataset_index_path}")
    
    # Statistiques des mots-cl√©s les plus fr√©quents
    word_freq = {word: len(entries) for word, entries in keyword_index.items()}
    top_words = sorted(word_freq.items(), key=lambda x: x[1], reverse=True)[:10]
    
    print("\nüîù Top 10 des mots-cl√©s:")
    for word, freq in top_words:
        print(f"  ‚Ä¢ {word}: {freq} occurrences")


def create_qa_search_tool():
    """Cr√©e un outil de recherche dans les Q&A."""
    
    search_tool_content = '''"""
Outil de recherche dans les Q&A g√©n√©r√©es.
Permet de trouver des questions/r√©ponses par mots-cl√©s.
"""

import json
import os
from typing import List, Dict, Any

class QASearchTool:
    """Outil de recherche dans la base de Q&A."""
    
    def __init__(self):
        """Initialise l'outil avec les index."""
        self.qa_catalog = self._load_catalog()
        self.keyword_index = self._load_keyword_index()
        self.dataset_index = self._load_dataset_index()
    
    def _load_catalog(self) -> List[Dict]:
        """Charge le catalogue complet."""
        try:
            with open("qa_visualizations/qa_catalog.json", 'r', encoding='utf-8') as f:
                return json.load(f)
        except:
            return []
    
    def _load_keyword_index(self) -> Dict:
        """Charge l'index par mots-cl√©s."""
        try:
            with open("qa_visualizations/keyword_index.json", 'r', encoding='utf-8') as f:
                return json.load(f)
        except:
            return {}
    
    def _load_dataset_index(self) -> Dict:
        """Charge l'index par dataset."""
        try:
            with open("qa_visualizations/dataset_index.json", 'r', encoding='utf-8') as f:
                return json.load(f)
        except:
            return {}
    
    def search_by_keyword(self, keyword: str) -> List[Dict]:
        """Recherche par mot-cl√©."""
        keyword = keyword.lower().strip()
        return self.keyword_index.get(keyword, [])
    
    def search_by_dataset(self, dataset: str) -> List[Dict]:
        """Recherche par dataset."""
        dataset = dataset.lower().strip()
        return self.dataset_index.get(dataset, [])
    
    def search_by_viz_type(self, viz_type: str) -> List[Dict]:
        """Recherche par type de visualisation."""
        results = []
        for qa in self.qa_catalog:
            if qa.get("viz_type", "").lower() == viz_type.lower():
                results.append(qa)
        return results
    
    def fuzzy_search(self, query: str) -> List[Dict]:
        """Recherche floue dans les questions."""
        query = query.lower()
        results = []
        
        for qa in self.qa_catalog:
            question = qa["question"].lower()
            response = qa["response"].lower()
            
            # Recherche dans question et r√©ponse
            if query in question or query in response:
                results.append(qa)
        
        return results
    
    def get_random_qa(self, n: int = 5) -> List[Dict]:
        """Retourne des Q&A al√©atoires."""
        import random
        return random.sample(self.qa_catalog, min(n, len(self.qa_catalog)))
    
    def get_stats(self) -> Dict:
        """Retourne les statistiques de la base."""
        return {
            "total_qa": len(self.qa_catalog),
            "datasets": list(self.dataset_index.keys()),
            "viz_types": list(set(qa.get("viz_type", "") for qa in self.qa_catalog)),
            "keywords": len(self.keyword_index)
        }

# Exemple d'utilisation
if __name__ == "__main__":
    search = QASearchTool()
    
    print("üîç Outil de recherche Q&A")
    print("=" * 30)
    
    # Statistiques
    stats = search.get_stats()
    print(f"üìä {stats['total_qa']} Q&A disponibles")
    print(f"üìÅ Datasets: {', '.join(stats['datasets'])}")
    print(f"üé® Types de viz: {', '.join(stats['viz_types'])}")
    
    # Recherche d'exemple
    print("\\nüîç Recherche 'ventes':")
    results = search.search_by_keyword("ventes")
    for result in results[:3]:
        print(f"  ‚Ä¢ {result['question']}")
    
    print("\\nüé≤ Q&A al√©atoires:")
    random_qa = search.get_random_qa(3)
    for qa in random_qa:
        print(f"  ‚Ä¢ {qa['question']} [{qa.get('dataset', 'N/A')}]")
'''
    
    with open("qa_search_tool.py", 'w', encoding='utf-8') as f:
        f.write(search_tool_content)
    
    print("üîç Outil de recherche cr√©√©: qa_search_tool.py")


if __name__ == "__main__":
    integrate_qa_to_chromadb()
    create_qa_search_tool()
    
    print("\nüéâ Int√©gration termin√©e !")
    print("üìÅ Fichiers cr√©√©s:")
    print("  ‚Ä¢ qa_visualizations/qa_catalog.json (59 Q&A)")
    print("  ‚Ä¢ qa_visualizations/keyword_index.json (index mots-cl√©s)")
    print("  ‚Ä¢ qa_visualizations/dataset_index.json (index datasets)")
    print("  ‚Ä¢ qa_search_tool.py (outil de recherche)")
    print("  ‚Ä¢ 59 fichiers PNG de visualisation")
    
    print("\nüí° Utilisation:")
    print("  python qa_search_tool.py  # Tester la recherche")
    print("  Int√©grez les Q&A dans votre chatbot local !")